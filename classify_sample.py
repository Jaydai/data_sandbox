#!/usr/bin/env python3
"""
Script pour classifier un Ã©chantillon de messages
"""
import argparse

from src.classification_pipeline import ClassificationPipeline
from src.storage import SupabaseResultWriter

def main():
    parser = argparse.ArgumentParser(description='Classifier un Ã©chantillon de messages')
    parser.add_argument(
        '--mode',
        choices=['sample', 'archive', 'responses', 'user'],
        default='sample',
        help="'sample' pour un Ã©chantillon, 'archive' pour tout Supabase, 'responses' pour analyser les rÃ©ponses, 'user' pour un utilisateur"
    )
    parser.add_argument(
        '--n-samples', 
        type=int, 
        default=1000,
        help='Nombre de messages Ã  classifier (mode sample)'
    )
    parser.add_argument(
        '--date',
        type=str,
        default=None,
        help="Date (YYYY-MM-DD) pour analyser les rÃ©ponses assistant"
    )
    parser.add_argument(
        '--user-id',
        type=str,
        default=None,
        help='Identifiant utilisateur pour le mode user'
    )
    parser.add_argument(
        '--model', 
        type=str, 
        default='mistral-small:latest',
        help='ModÃ¨le Ã  utiliser (Ollama ou HF)'
    )
    parser.add_argument(
        '--engine',
        choices=['ollama', 'hf'],
        default='ollama',
        help="Backend d'infÃ©rence (ollama local ou hf via router)"
    )
    parser.add_argument(
        '--use-context',
        action='store_true',
        help='Utiliser le contexte des messages prÃ©cÃ©dents'
    )
    parser.add_argument(
        '--subfolder',
        type=str,
        default='messages',
        help="Sous-dossier Supabase (messages ou chats) en mode archive"
    )
    parser.add_argument(
        '--sample-fraction',
        type=float,
        default=1.0,
        help='Fraction alÃ©atoire lors du chargement par date (mode responses)'
    )
    parser.add_argument(
        '--max-files',
        type=int,
        default=None,
        help='Nombre maximum de fichiers Ã  parcourir (mode user)'
    )
    parser.add_argument(
        '--overwrite',
        action='store_true',
        help='Ã‰crase les fichiers dÃ©jÃ  classifiÃ©s (mode archive)'
    )
    parser.add_argument(
        '--store-supabase',
        action='store_true',
        help='Enregistrer les messages enrichis dans Supabase SQL'
    )
    parser.add_argument(
        '--supabase-table',
        type=str,
        default=None,
        help='Nom de la table destination (sinon SUPABASE_RESULTS_TABLE)'
    )
    parser.add_argument(
        '--supabase-batch-size',
        type=int,
        default=500,
        help='Taille des batchs lors de lÃ©criture Supabase'
    )
    
    args = parser.parse_args()
    
    date_info = args.date if args.date else 'N/A'
    user_info = args.user_id if args.user_id else 'N/A'
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          CLASSIFICATION DE MESSAGES CHATGPT                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ› Mode : {args.mode}
ğŸ“Š Taille Ã©chantillon : {args.n_samples if args.mode == 'sample' else 'tous les fichiers'}
ğŸ¤– ModÃ¨le : {args.model}
ğŸ”— Contexte : {'âœ… ActivÃ©' if args.use_context else 'âŒ DÃ©sactivÃ©'}
 ğŸ“… Date ciblÃ©e : {date_info}
 ğŸ‘¤ Utilisateur : {user_info}

""")
    
    # Initialiser le pipeline
    supabase_writer = None
    if args.store_supabase:
        supabase_writer = SupabaseResultWriter(
            table_name=args.supabase_table,
            batch_size=args.supabase_batch_size,
        )
    pipeline = ClassificationPipeline(
        model=args.model,
        engine=args.engine,
        store_in_supabase=args.store_supabase,
        supabase_writer=supabase_writer,
    )

    if args.mode == 'responses':
        if not args.date:
            raise SystemExit("--date est requis pour le mode responses")
        pipeline.analyze_responses_for_date(
            date=args.date,
            subfolder=args.subfolder,
            sample_fraction=args.sample_fraction,
            use_context=args.use_context,
            overwrite=args.overwrite,
        )
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 âœ… ANALYSE RÃ‰PONSES TERMINÃ‰E                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“… Date : {args.date}
ğŸ“ RÃ©sultats : {pipeline.output_dir}/{args.subfolder}/date={args.date}

""")
        return

    if args.mode == 'user':
        if not args.user_id:
            raise SystemExit("--user-id est requis pour le mode user")
        pipeline.analyze_user_conversation(
            user_id=args.user_id,
            subfolder=args.subfolder,
            sample_fraction=args.sample_fraction,
            max_files=args.max_files,
            use_context=args.use_context,
            overwrite=args.overwrite,
        )
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 âœ… ANALYSE UTILISATEUR TERMINÃ‰E               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‘¤ Utilisateur : {args.user_id}
ğŸ“ RÃ©sultats : {pipeline.output_dir}/{args.subfolder}/users/{args.user_id}

""")
        return

    if args.mode == 'archive':
        pipeline.run_full_archive_classification(
            use_context=args.use_context,
            subfolder=args.subfolder,
            overwrite=args.overwrite
        )
        output_target = pipeline.output_dir / args.subfolder
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     âœ… ARCHIVE TRAITÃ‰E                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ RÃ©sultats sauvegardÃ©s dans : {output_target}
ğŸ‘‰ Relancez avec --overwrite pour rÃ©gÃ©nÃ©rer un fichier existant

""")
        return

    # Mode sample
    results = pipeline.run_sample_classification(
        n_samples=args.n_samples,
        use_context=args.use_context
    )
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     âœ… CLASSIFICATION TERMINÃ‰E                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ RÃ©sultats sauvegardÃ©s dans : data/processed/
ğŸ“Š {len(results)} messages classifiÃ©s

Prochaines Ã©tapes :
  1. Visualiser : python analyze_results.py
  2. Valider manuellement : python validate_sample.py
  3. Classifier plus de messages : python classify_sample.py --mode archive

""")

if __name__ == "__main__":
    main()
