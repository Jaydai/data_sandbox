import ollama
import json
import logging
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

class LocalMessageClassifier:
    """
    Classifier utilisant des mod√®les open-source locaux via Ollama
    """
    
    def __init__(self, model: str = "qwen2.5:14b"):
        """
        Args:
            model: Nom du mod√®le Ollama √† utiliser
                   Options: "llama3.3:70b", "llama3.1:8b", "qwen2.5:14b"
        """
        self.model = model
        
        try:
            # Test simple : essayer de faire un appel au mod√®le
            logger.info(f"üîç V√©rification du mod√®le {model}...")
            
            test_response = ollama.chat(
                model=self.model,
                messages=[{'role': 'user', 'content': 'Test'}],
                options={'num_predict': 5}
            )
            
            logger.info(f"‚úÖ Classifier initialis√© avec {model}")
            
        except ollama.ResponseError as e:
            if "model" in str(e).lower() and "not found" in str(e).lower():
                logger.warning(f"‚ö†Ô∏è  Mod√®le {model} non trouv√©.")
                logger.info(f"‚¨áÔ∏è  T√©l√©chargement de {model}... (cela peut prendre quelques minutes)")
                ollama.pull(model)
                logger.info(f"‚úÖ Mod√®le {model} t√©l√©charg√© et pr√™t")
            else:
                logger.error(f"‚ùå Erreur: {e}")
                raise
        
        except Exception as e:
            logger.error(f"‚ùå Erreur d'initialisation: {e}")
            raise
    
    def _call_ollama(
        self, 
        system_prompt: str, 
        user_message: str, 
        temperature: float = 0.0
    ) -> str:
        """
        Appel au mod√®le Ollama local
        
        Args:
            system_prompt: Instructions syst√®me
            user_message: Message √† classifier
            temperature: Cr√©ativit√© (0 = d√©terministe)
        
        Returns:
            R√©ponse du mod√®le
        """
        try:
            response = ollama.chat(
                model=self.model,
                messages=[
                    {
                        'role': 'system',
                        'content': system_prompt
                    },
                    {
                        'role': 'user',
                        'content': user_message
                    }
                ],
                options={
                    'temperature': temperature,
                    'num_predict': 500  # √âquivalent de max_tokens
                }
            )
            
            return response['message']['content']
        
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'appel au mod√®le: {e}")
            return ""
    
    def _clean_json_response(self, response: str) -> str:
        """Nettoie la r√©ponse pour extraire le JSON"""
        response = response.strip()
        
        # Enlever les balises markdown
        if response.startswith('```json'):
            response = response[7:]
        elif response.startswith('```'):
            response = response[3:]
        
        if response.endswith('```'):
            response = response[:-3]
        
        response = response.strip()
        
        # Si pas de JSON trouv√©, chercher entre accolades
        if not response.startswith('{'):
            start = response.find('{')
            end = response.rfind('}')
            if start != -1 and end != -1:
                response = response[start:end+1]
        
        return response
    
    def classify_work_related(self, content: str, context: str = "") -> Dict:
        """
        Classifier Work / Non-Work
        """
        system_prompt = """Tu es un expert en analyse de messages envoy√©s √† des IA.
Ta t√¢che est de d√©terminer si un message est li√© au TRAVAIL PROFESSIONNEL ou non.

D√âFINITION DE "TRAVAIL" :
- Messages li√©s √† une activit√© professionnelle r√©mun√©r√©e
- Emails professionnels, rapports, pr√©sentations
- Analyse de donn√©es, code pour le travail
- Communication avec coll√®gues/clients
- Recherche d'informations pour des projets professionnels

PAS DU TRAVAIL :
- Questions personnelles (sant√©, loisirs, recettes)
- Apprentissage personnel sans lien avec le travail
- Divertissement, jeux, conversations sociales
- Aide aux devoirs (sauf si l'utilisateur est enseignant)

IMPORTANT : R√©ponds UNIQUEMENT avec un JSON valide, sans texte avant ou apr√®s.
Format exact :
{
    "is_work": true,
    "confidence": "high",
    "reasoning": "explication br√®ve en une phrase"
}"""

        full_message = f"""MESSAGE √Ä CLASSIFIER :
{content}

{f"CONTEXTE (messages pr√©c√©dents) : {context}" if context else ""}

R√©ponds uniquement avec le JSON, rien d'autre."""

        response = self._call_ollama(system_prompt, full_message)
        response = self._clean_json_response(response)
        
        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de parsing JSON: {response[:200]}")
            return {"is_work": False, "confidence": "low", "reasoning": "Erreur de classification"}
    
    def classify_topic(self, content: str, context: str = "") -> Dict:
        """
        Classifier le sujet principal du message
        """
        system_prompt = """Tu es un expert en analyse de messages envoy√©s √† des IA.
Ta t√¢che est de classifier le SUJET PRINCIPAL du message.

CAT√âGORIES PRINCIPALES (choisis UNE seule) :

1. WRITING : R√©daction, √©dition, traduction de texte
2. PRACTICAL_GUIDANCE : Conseils pratiques, tutorat, id√©es cr√©atives
3. SEEKING_INFORMATION : Recherche d'informations factuelles
4. TECHNICAL_HELP : Programmation, maths, analyse de donn√©es
5. MULTIMEDIA : Cr√©ation/analyse d'images ou autres m√©dias
6. SELF_EXPRESSION : Conversations sociales, r√©flexions personnelles
7. OTHER : Autre ou ambig√º

IMPORTANT : R√©ponds UNIQUEMENT avec un JSON valide.
Format exact :
{
    "topic": "WRITING",
    "sub_topic": "description plus pr√©cise",
    "confidence": "high"
}"""

        full_message = f"""MESSAGE √Ä CLASSIFIER :
{content}

{f"CONTEXTE : {context}" if context else ""}

R√©ponds uniquement avec le JSON."""

        response = self._call_ollama(system_prompt, full_message)
        response = self._clean_json_response(response)
        
        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            logger.error(f"Erreur de parsing JSON: {response[:200]}")
            return {"topic": "OTHER", "sub_topic": "unknown", "confidence": "low"}
    
    def classify_intent(self, content: str, context: str = "") -> Dict:
        """
        Classifier l'intention : Asking / Doing / Expressing
        """
        system_prompt = """Tu es un expert en analyse d'intentions dans les messages.

D√âFINITIONS :

1. ASKING : Cherche des informations ou conseils pour prendre une d√©cision
   Exemples : "Comment faire X?", "Quelle est la diff√©rence entre Y et Z?"

2. DOING : Demande de PRODUIRE quelque chose (texte, code, etc.)
   Exemples : "√âcris un email", "Cr√©e un tableau", "Traduis ce texte"

3. EXPRESSING : Expression de sentiments sans attente d'action
   Exemples : "Bonjour!", "Je suis content", salutations

IMPORTANT : R√©ponds UNIQUEMENT avec un JSON valide.
Format exact :
{
    "intent": "ASKING",
    "confidence": "high",
    "reasoning": "br√®ve explication"
}"""

        full_message = f"""MESSAGE √Ä CLASSIFIER :
{content}

{f"CONTEXTE : {context}" if context else ""}

R√©ponds uniquement avec le JSON."""

        response = self._call_ollama(system_prompt, full_message)
        response = self._clean_json_response(response)
        
        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            logger.error(f"Erreur de parsing JSON: {response[:200]}")
            return {"intent": "EXPRESSING", "confidence": "low", "reasoning": "Erreur"}
    
    def classify_complete(self, content: str, context: str = "") -> Dict:
        """
        Classification compl√®te d'un message
        """
        logger.info(f"üîç Classification compl√®te du message ({len(content)} caract√®res)...")
        
        # Tronquer si trop long
        content_truncated = content[:5000] if len(content) > 5000 else content
        context_truncated = context[:2000] if len(context) > 2000 else context
        
        results = {
            "work": self.classify_work_related(content_truncated, context_truncated),
            "topic": self.classify_topic(content_truncated, context_truncated),
            "intent": self.classify_intent(content_truncated, context_truncated)
        }
        
        logger.info(f"‚úÖ Classification termin√©e")
        return results


# Fonction helper
def classify_message_local(content: str, context: str = "", model: str = "qwen2.5:14b") -> Dict:
    """Classification rapide avec mod√®le local"""
    classifier = LocalMessageClassifier(model=model)
    return classifier.classify_complete(content, context)